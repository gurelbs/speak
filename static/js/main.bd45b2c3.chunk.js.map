{"version":3,"sources":["App.js","reportWebVitals.js","index.js"],"names":["App","useState","answer","setAnswer","useEffect","speak","SpeechSynthesisUtterance","window","webkitSpeechSynthesisUtterance","console","log","speechSynthesis","getVoices","webkitSpeechSynthesis","className","onClick","recognition","speechRecognition","webkitSpeechRecognition","start","onresult","e","current","resultIndex","transcript","results","mobileRepeatBug","onend","reportWebVitals","onPerfEntry","Function","then","getCLS","getFID","getFCP","getLCP","getTTFB","ReactDOM","render","StrictMode","document","getElementById"],"mappings":"8LAGe,SAASA,IACtB,MAA4BC,mBAAS,IAArC,mBAAOC,EAAP,KAAeC,EAAf,KAgCA,OA9BAC,qBAAU,WACR,GAAIF,EAAO,CACT,IAAMG,EAAQ,IAAKC,0BAA6BC,OAAOD,0BAA4BC,OAAOC,gCAAgCN,GAC1HO,QAAQC,IAAIH,OAAOI,gBAAgBC,aACnCD,gBAAgBN,MAAMA,GAClBE,OAAOI,iBACTJ,OAAOI,gBAAgBN,MAAMA,GAE3BE,OAAOM,uBACTN,OAAOM,sBAAsBR,MAAMA,MAGvC,CAACH,IAmBD,sBAAKY,UAAU,aAAf,UACE,wBAAQC,QAlBZ,WACE,IAAMC,EAAc,IAAKT,OAAOU,mBAAqBV,OAAOW,yBAC5DF,EAAYG,QACZH,EAAYI,SAAW,SAACC,GACtB,IAAMC,EAAUD,EAAEE,YACdC,EAAaH,EAAEI,QAAQH,GAAS,GAAGE,WACvCrB,EAAUqB,GACV,IAAIE,EAA+B,IAAZJ,GAAiBE,IAAeH,EAAEI,QAAQ,GAAG,GAAGD,WACpEE,GACDjB,QAAQC,IAAIgB,GAEdV,EAAYW,MAAQ,WAClBlB,QAAQC,IAAI,8CAMd,oGACCR,KCvCP,IAYe0B,EAZS,SAAAC,GAClBA,GAAeA,aAAuBC,UACxC,6BAAqBC,MAAK,YAAkD,IAA/CC,EAA8C,EAA9CA,OAAQC,EAAsC,EAAtCA,OAAQC,EAA8B,EAA9BA,OAAQC,EAAsB,EAAtBA,OAAQC,EAAc,EAAdA,QAC3DJ,EAAOH,GACPI,EAAOJ,GACPK,EAAOL,GACPM,EAAON,GACPO,EAAQP,OCDdQ,IAASC,OACP,cAAC,IAAMC,WAAP,UACE,cAAC,EAAD,MAEFC,SAASC,eAAe,SAM1Bb,K","file":"static/js/main.bd45b2c3.chunk.js","sourcesContent":["import React, { useState, useEffect } from 'react';\nimport './App.css';\n\nexport default function App() {\n  const [answer, setAnswer] = useState('')\n\n  useEffect(() => {\n    if (answer){\n      const speak = new (SpeechSynthesisUtterance ||  window.SpeechSynthesisUtterance || window.webkitSpeechSynthesisUtterance)(answer);\n      console.log(window.speechSynthesis.getVoices());\n      speechSynthesis.speak(speak)\n      if (window.speechSynthesis){\n        window.speechSynthesis.speak(speak)\n      }\n      if (window.webkitSpeechSynthesis){\n        window.webkitSpeechSynthesis.speak(speak)\n      }\n    }\n  },[answer])\n\n  function handleReco(){\n    const recognition = new (window.speechRecognition || window.webkitSpeechRecognition)();\n    recognition.start()\n    recognition.onresult = (e) => {\n      const current = e.resultIndex;\n      let transcript = e.results[current][0].transcript;\n      setAnswer(transcript)\n      let mobileRepeatBug = (current === 1 && transcript === e.results[0][0].transcript);\n      if(mobileRepeatBug) {\n        console.log(mobileRepeatBug);\n      }\n      recognition.onend = () => {\n        console.log('Speech recognition service disconnected');\n      }\n    }\n  }\n  return (\n    <div className=\"App-header\">\n      <button onClick={handleReco}>התחלת זיהוי קולי</button>\n      {answer}\n    </div>\n  );\n}\n","const reportWebVitals = onPerfEntry => {\n  if (onPerfEntry && onPerfEntry instanceof Function) {\n    import('web-vitals').then(({ getCLS, getFID, getFCP, getLCP, getTTFB }) => {\n      getCLS(onPerfEntry);\n      getFID(onPerfEntry);\n      getFCP(onPerfEntry);\n      getLCP(onPerfEntry);\n      getTTFB(onPerfEntry);\n    });\n  }\n};\n\nexport default reportWebVitals;\n","import React from 'react';\nimport ReactDOM from 'react-dom';\nimport './index.css';\nimport App from './App';\nimport reportWebVitals from './reportWebVitals';\n\nReactDOM.render(\n  <React.StrictMode>\n    <App />\n  </React.StrictMode>,\n  document.getElementById('root')\n);\n\n// If you want to start measuring performance in your app, pass a function\n// to log results (for example: reportWebVitals(console.log))\n// or send to an analytics endpoint. Learn more: https://bit.ly/CRA-vitals\nreportWebVitals();\n"],"sourceRoot":""}